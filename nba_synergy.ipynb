{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d2cd8a",
   "metadata": {},
   "source": [
    "# Load the NBA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52616e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /Users/rahulkarthikt/.cache/kagglehub/datasets/szymonjwiak/nba-play-by-play-data-1997-2023/versions/1\n",
      "First 5 records:      gameid  period        clock  h_pts  a_pts team  playerid      player  \\\n",
      "0  20900001       1  PT12M00.00S    0.0    0.0  NaN         0         NaN   \n",
      "1  20900001       1  PT12M00.00S    NaN    NaN  CLE       406   S. O'Neal   \n",
      "2  20900001       1  PT11M31.00S    2.0    0.0  CLE      2760  A. Varejao   \n",
      "3  20900001       1  PT11M12.00S    NaN    NaN  BOS       951    R. Allen   \n",
      "4  20900001       1  PT11M10.00S    NaN    NaN  CLE       406   S. O'Neal   \n",
      "\n",
      "          type              subtype  result    x   y  dist  \\\n",
      "0       period                start     NaN    0   0     0   \n",
      "1    Jump Ball                  NaN     NaN    0   0     0   \n",
      "2    Made Shot  Step Back Jump shot    Made   36  93    10   \n",
      "3  Missed Shot            Jump Shot  Missed  214  83    23   \n",
      "4      Rebound              Unknown     NaN    0   0     0   \n",
      "\n",
      "                                                desc  season  \n",
      "0                  Start of 1st Period (7:34 PM EST)    2010  \n",
      "1       Jump Ball O'Neal vs. Perkins: Tip to Varejao    2010  \n",
      "2  Varejao 10' Step Back Jump Shot (2 PTS) (O'Nea...    2010  \n",
      "3                           MISS Allen 23' Jump Shot    2010  \n",
      "4                       O'Neal REBOUND (Off:0 Def:1)    2010  \n",
      "Columns: ['gameid', 'period', 'clock', 'h_pts', 'a_pts', 'team', 'playerid', 'player', 'type', 'subtype', 'result', 'x', 'y', 'dist', 'desc', 'season']\n",
      "First 5 records:      gameid  period        clock  h_pts  a_pts team  playerid      player  \\\n",
      "0  20900001       1  PT12M00.00S    0.0    0.0  NaN         0         NaN   \n",
      "1  20900001       1  PT12M00.00S    NaN    NaN  CLE       406   S. O'Neal   \n",
      "2  20900001       1  PT11M31.00S    2.0    0.0  CLE      2760  A. Varejao   \n",
      "3  20900001       1  PT11M12.00S    NaN    NaN  BOS       951    R. Allen   \n",
      "4  20900001       1  PT11M10.00S    NaN    NaN  CLE       406   S. O'Neal   \n",
      "\n",
      "          type              subtype  result    x   y  dist  \\\n",
      "0       period                start     NaN    0   0     0   \n",
      "1    Jump Ball                  NaN     NaN    0   0     0   \n",
      "2    Made Shot  Step Back Jump shot    Made   36  93    10   \n",
      "3  Missed Shot            Jump Shot  Missed  214  83    23   \n",
      "4      Rebound              Unknown     NaN    0   0     0   \n",
      "\n",
      "                                                desc  season  \n",
      "0                  Start of 1st Period (7:34 PM EST)    2010  \n",
      "1       Jump Ball O'Neal vs. Perkins: Tip to Varejao    2010  \n",
      "2  Varejao 10' Step Back Jump Shot (2 PTS) (O'Nea...    2010  \n",
      "3                           MISS Allen 23' Jump Shot    2010  \n",
      "4                       O'Neal REBOUND (Off:0 Def:1)    2010  \n",
      "Columns: ['gameid', 'period', 'clock', 'h_pts', 'a_pts', 'team', 'playerid', 'player', 'type', 'subtype', 'result', 'x', 'y', 'dist', 'desc', 'season']\n"
     ]
    }
   ],
   "source": [
    "import kagglehub  # spell-checker: ignore\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = kagglehub.dataset_download(\"szymonjwiak/nba-play-by-play-data-1997-2023\")  # spell-checker: ignore\n",
    "\n",
    "print(\"Dataset downloaded to:\", path)\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, 'pbp2010.csv'))\n",
    "\n",
    "print(\"First 5 records:\", df.head())\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3469280",
   "metadata": {},
   "source": [
    "# Process Data for Synergy Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44241b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player stats sample:\n",
      "   playerid  season     pts    reb  ast\n",
      "0       255    2010  3120.0  538.0  0.0\n",
      "1       255    2011  3663.0  338.0  0.0\n",
      "2       255    2012  1480.0  171.0  0.0\n",
      "3       283    2010    13.0   14.0  0.0\n",
      "4       406    2010  2386.0  416.0  0.0\n",
      "Duo data sample:\n",
      "   player_a  player_b  season    pts_a  reb_a  ast_a    pts_b  reb_b  ast_b  \\\n",
      "0      2544    201142    2010  14385.0  656.0    0.0  13737.0  669.0    0.0   \n",
      "1      2544       977    2010  14385.0  656.0    0.0  14663.0  529.0    0.0   \n",
      "2      2544      2548    2010  14385.0  656.0    0.0  11750.0  401.0    0.0   \n",
      "3      2544      2546    2010  14385.0  656.0    0.0  11935.0  505.0    0.0   \n",
      "4      2544      1717    2010  14385.0  656.0    0.0  10897.0  669.0    0.0   \n",
      "\n",
      "   combined_pts  combined_reb  combined_ast  net_rating  \n",
      "0       28122.0        1325.0           0.0   -1.750583  \n",
      "1       29048.0        1185.0           0.0   -3.016684  \n",
      "2       26135.0        1057.0           0.0   -1.530349  \n",
      "3       26320.0        1161.0           0.0   -1.311335  \n",
      "4       25282.0        1325.0           0.0   -4.290335  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "path = '/Users/rahulkarthikt/.cache/kagglehub/datasets/szymonjwiak/nba-play-by-play-data-1997-2023/versions/1'  # spell-checker: ignore\n",
    "\n",
    "years = [2010, 2011, 2012]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    df = pd.read_csv(os.path.join(path, f'pbp{year}.csv'))\n",
    "    dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Calculate player stats\n",
    "\n",
    "# Points\n",
    "df_shots = df_all[df_all['type'] == 'Made Shot']\n",
    "df_shots = df_shots.copy()\n",
    "df_shots['pts'] = df_shots['desc'].str.extract(r'\\((\\d+) PTS\\)')[0].astype(float)\n",
    "player_pts = df_shots.groupby(['playerid', 'season'])['pts'].sum().reset_index(name='pts')  # spell-checker: ignore\n",
    "\n",
    "# Rebounds\n",
    "df_rebounds = df_all[df_all['type'] == 'Rebound']\n",
    "player_reb = df_rebounds.groupby(['playerid', 'season']).size().reset_index(name='reb')  # spell-checker: ignore\n",
    "\n",
    "# Assists\n",
    "df_assists = df_all[df_all['subtype'] == 'Assist']\n",
    "player_ast = df_assists.groupby(['playerid', 'season']).size().reset_index(name='ast')  # spell-checker: ignore\n",
    "\n",
    "# Merge\n",
    "player_stats = player_pts.merge(player_reb, on=['playerid', 'season'], how='outer').merge(player_ast, on=['playerid', 'season'], how='outer').fillna(0)\n",
    "\n",
    "print(\"Player stats sample:\")\n",
    "print(player_stats.head())\n",
    "\n",
    "# For duo net rating, simplified calculation\n",
    "# For demonstration, create synthetic duos and net rating\n",
    "\n",
    "# Take top players\n",
    "top_players = player_stats.groupby('playerid')['pts'].sum().nlargest(20).index\n",
    "\n",
    "duo_list = []\n",
    "\n",
    "for i in range(len(top_players)):\n",
    "    for j in range(i+1, len(top_players)):\n",
    "        duo_list.append((top_players[i], top_players[j]))\n",
    "\n",
    "duo_df = pd.DataFrame(duo_list, columns=['player_a', 'player_b'])\n",
    "\n",
    "# Add season, assume 2010\n",
    "duo_df['season'] = 2010\n",
    "\n",
    "# Merge stats\n",
    "player_a_stats = player_stats.rename(columns={'playerid': 'player_a', 'pts': 'pts_a', 'reb': 'reb_a', 'ast': 'ast_a'})  # spell-checker: ignore\n",
    "player_b_stats = player_stats.rename(columns={'playerid': 'player_b', 'pts': 'pts_b', 'reb': 'reb_b', 'ast': 'ast_b'})  # spell-checker: ignore\n",
    "\n",
    "duo_df = duo_df.merge(player_a_stats[['player_a', 'season', 'pts_a', 'reb_a', 'ast_a']], on=['player_a', 'season'], how='left', validate='many_to_one')\n",
    "duo_df = duo_df.merge(player_b_stats[['player_b', 'season', 'pts_b', 'reb_b', 'ast_b']], on=['player_b', 'season'], how='left', validate='many_to_one')\n",
    "\n",
    "# Combined features\n",
    "duo_df['combined_pts'] = duo_df['pts_a'] + duo_df['pts_b']\n",
    "duo_df['combined_reb'] = duo_df['reb_a'] + duo_df['reb_b']\n",
    "duo_df['combined_ast'] = duo_df['ast_a'] + duo_df['ast_b']\n",
    "\n",
    "# Synthetic target: net rating as a function of combined stats\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(42)\n",
    "duo_df['net_rating'] = (duo_df['combined_pts'] + duo_df['combined_reb'] + duo_df['combined_ast']) / 10000 - 5 + rng.normal(0, 1, len(duo_df))\n",
    "\n",
    "print(\"Duo data sample:\")\n",
    "print(duo_df.head())\n",
    "\n",
    "X = duo_df[['combined_pts', 'combined_reb', 'combined_ast']]\n",
    "y = duo_df['net_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71dce6",
   "metadata": {},
   "source": [
    "# Build the Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77fbc175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad719482",
   "metadata": {},
   "source": [
    "# Evaluate the Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d7db28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.8962178453075399\n",
      "R-squared: 0.1584398097906865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95cf23c",
   "metadata": {},
   "source": [
    "# Create Synergy Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e207b521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synergy_class\n",
      "1    126\n",
      "0     64\n",
      "2      0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duo_df['synergy_class'] = pd.cut(duo_df['net_rating'], bins=[-float('inf'), -3.5, 3.5, float('inf')], labels=[0, 1, 2])\n",
    "\n",
    "print(duo_df['synergy_class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84810a66",
   "metadata": {},
   "source": [
    "# Train the Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11d2f79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_class = duo_df['synergy_class']\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "log_model.fit(X_train_c, y_train_c)\n",
    "\n",
    "print(\"Logistic Regression trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2037230",
   "metadata": {},
   "source": [
    "# Train the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca0e315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(ccp_alpha=0.0)\n",
    "\n",
    "dt_model.fit(X_train_c, y_train_c)\n",
    "\n",
    "print(\"Decision Tree trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06acacf",
   "metadata": {},
   "source": [
    "# Evaluate the Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11fe2411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6578947368421053\n",
      "Decision Tree Accuracy: 0.5789473684210527\n",
      "Logistic Regression CV Mean: 0.6736842105263158\n",
      "Decision Tree CV Mean: 0.5473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "log_pred = log_model.predict(X_test_c)\n",
    "dt_pred = dt_model.predict(X_test_c)\n",
    "\n",
    "log_acc = accuracy_score(y_test_c, log_pred)\n",
    "dt_acc = accuracy_score(y_test_c, dt_pred)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {log_acc}\")\n",
    "print(f\"Decision Tree Accuracy: {dt_acc}\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "log_cv = cross_val_score(log_model, X, y_class, cv=kf)\n",
    "dt_cv = cross_val_score(dt_model, X, y_class, cv=kf)\n",
    "\n",
    "print(f\"Logistic Regression CV Mean: {log_cv.mean()}\")\n",
    "print(f\"Decision Tree CV Mean: {dt_cv.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4fa00",
   "metadata": {},
   "source": [
    "# Compare Models with McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b268044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table (McNemar): [[19, 3], [6, 10]]\n",
      "McNemar's test statistic: 3.0\n",
      "p-value: 0.5078125\n",
      "No significant difference between models (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "# Build contingency table\n",
    "table = [[0, 0], [0, 0]]\n",
    "for i in range(len(y_test_c)):\n",
    "    if y_test_c.iloc[i] == dt_pred[i] and y_test_c.iloc[i] != log_pred[i]:\n",
    "        table[0][1] += 1\n",
    "    elif y_test_c.iloc[i] != dt_pred[i] and y_test_c.iloc[i] == log_pred[i]:\n",
    "        table[1][0] += 1\n",
    "\n",
    "for i in range(len(y_test_c)):\n",
    "    if y_test_c.iloc[i] == dt_pred[i] and y_test_c.iloc[i] == log_pred[i]:\n",
    "        table[0][0] += 1\n",
    "    elif y_test_c.iloc[i] != dt_pred[i] and y_test_c.iloc[i] != log_pred[i]:\n",
    "        table[1][1] += 1\n",
    "\n",
    "print(\"Contingency Table (McNemar):\", table)\n",
    "\n",
    "# Run McNemar's test\n",
    "result = mcnemar(table, exact=True)  \n",
    "stat = getattr(result, 'statistic')\n",
    "pval = getattr(result, 'pvalue')\n",
    "\n",
    "print(f\"McNemar's test statistic: {stat}\")\n",
    "print(f\"p-value: {pval}\")\n",
    "\n",
    "if pval < 0.05:\n",
    "    print(\"Significant difference between models (reject H0)\")\n",
    "else:\n",
    "    print(\"No significant difference between models (fail to reject H0)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
